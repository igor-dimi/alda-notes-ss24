[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Algorithms & Data Structures Notes - SoSe 24",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "02-intro/02-analysis.html",
    "href": "02-intro/02-analysis.html",
    "title": "1  Program Run-time Analysis",
    "section": "",
    "text": "1.1 Reccurence Relations\nConsider a very simple reccurence relation:\n\\[\n    T(n) :=\n    \\begin{cases}\n        1               & n = 1 \\\\\n        n + T(n - 1),   & n &gt; 1\n    \\end{cases}\n\\]\nWith mathematical induction we can formally show that \\(T(n)\\) is quadratic. But there is a simpler & more intuitive way:\n\\[\\begin{align*}\n    T(n) &= n + T(n - 1)            \\tag{Def $T(\\cdot)$} \\\\\n         &= n + n - 1 + T(n - 2)  \\\\\n         &= \\dots \\tag{Repeat $n - 2$ times}\\\\\n         &= n + n - 1 + \\dots + T(1) \\\\\n         &= n + n - 1 + \\dots + 1 \\tag{Def $T(1)$} \\\\\n         &= \\frac{n(n + 1)}{2} \\tag{Gauss}\\\\\n         &\\in \\mathcal{O}(n^2)\n\\end{align*}\\]\nThis method can be applied to the more complex divide-and-conquer reccurence relation from the lecture:\n\\[\n    R(n) :=\n    \\begin{cases}\n        a, &n = 1 \\\\\n        c\\dot n + d\\cdot R(\\frac{n}{b}), &n &gt; 1\n    \\end{cases}\n\\]\nApplying the above method we expand \\(R(\\cdot)\\) repetitively according to its definition until we reach the base case, rearranging terms when necessary:\n\\[\\begin{align*}\n    R(n) &= c\\cdot n + d\\cdot R(\\frac{n}{b}) \\tag{Def $R(\\cdot)$} \\\\\n         &= c\\cdot n + d\\bigl(c\\frac{n}{b} + d\\cdot R(\\frac{n}{b^2})\\bigr)  \\\\\n         &= c\\cdot n + d\\Bigl(c\\frac{n}{b} + d\\cdot \\bigl(c\\cdot \\frac{n}{b^2} + d\\cdot R(\\frac{n}{b^2})\\bigr)\\Bigr)  \\\\\n         &= c\\cdot n + d\\cdot c\\frac{n}{b} + d^2c\\frac{n}{b^2} + d^3\\cdot R(\\frac{n}{b^3}) \\tag{Rearrange} \\\\\n         &= c\\cdot n \\left(1 + \\frac{d}{b} + \\frac{d^2}{b^2}\\right) + d^3\\cdot R(\\frac{n}{b^3}) \\\\\n         &= \\dots \\tag{Repeat $k$-times} \\\\\n         &= c\\cdot n\\left(1 + \\frac{d}{b} + \\dots + \\frac{d^{k - 1}}{b^{k - 1}}\\right) + d^k \\cdot R(\\frac{n}{b^k}) \\\\\n         &= c\\cdot n \\sum_{i = 0}^{k - 1}\\left(\\frac{d}{b}\\right)^i + d^k \\cdot R(\\frac{n}{b^k}) \\\\\n         &= c\\cdot n \\sum_{i = 0}^{k - 1}\\left(\\frac{d}{b}\\right)^i + d^k \\cdot R(1) \\tag{Ass $\\frac{n}{b^k} = 1$} \\\\\n         &= c\\cdot n \\sum_{i = 0}^{k - 1}\\left(\\frac{d}{b}\\right)^i + a\\cdot d^k \\tag{Def $R(1)$}\n\\end{align*}\\]\nSee lecture slides for the complexity analysis of final expression.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Program Run-time Analysis</span>"
    ]
  },
  {
    "objectID": "02-intro/02-analysis.html#master-theorem",
    "href": "02-intro/02-analysis.html#master-theorem",
    "title": "1  Program Run-time Analysis",
    "section": "1.2 Master Theorem",
    "text": "1.2 Master Theorem\nFor reccurence relations of the form:\n\\[\n    T(n) :=\n    \\begin{cases}\n        a, &n = 1 \\\\\n        b\\cdot n + c\\cdot T(\\frac{n}{d}), &n &gt; 1\n    \\end{cases}\n\\]\nMaster theorem gives the solutions:\n\\[\n    T(n) =\n    \\begin{cases}\n        \\Theta(n), &c &lt; d \\\\\n        \\Theta(n\\log(n)), &c = d \\\\\n        \\Theta(n^{\\log_b(d)}), &c &gt; d \\\\\n    \\end{cases}\n\\]\nExample: Merge Sort.\nComplexity of merge sort satisfies the reccurence relation:\n\\[\\begin{align*}\n&T(1) = 1 \\\\\n&T(n) = \\mathcal{O}(n) + 2\\cdot T(\\frac{n}{2})\n\\end{align*}\\]\nThus with \\(c = 2 = d\\) the second case of MT applies: \\(T(n) = \\Theta(n\\log n)\\)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Program Run-time Analysis</span>"
    ]
  },
  {
    "objectID": "02-intro/02-analysis.html#amortized-analysis",
    "href": "02-intro/02-analysis.html#amortized-analysis",
    "title": "1  Program Run-time Analysis",
    "section": "1.3 Amortized Analysis",
    "text": "1.3 Amortized Analysis",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Program Run-time Analysis</span>"
    ]
  },
  {
    "objectID": "03/01-lists.html",
    "href": "03/01-lists.html",
    "title": "2  Lists",
    "section": "",
    "text": "2.1 Sequences as Arrays and Lists\nMany terms for same thing: sequence, field, list, stack, string, file… Yes, files are simply sequences of bytes!\nthree views on lists:",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lists</span>"
    ]
  },
  {
    "objectID": "03/01-lists.html#sequences-as-arrays-and-lists",
    "href": "03/01-lists.html#sequences-as-arrays-and-lists",
    "title": "2  Lists",
    "section": "",
    "text": "abstract: \\((2, 3, 5, 7)\\)\nfunctionality: stack, queue, etc… What operations does it support?\nrepresentation: How is the list represented in a given programming model/language/paradigm?",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lists</span>"
    ]
  },
  {
    "objectID": "03/01-lists.html#applications-of-lists",
    "href": "03/01-lists.html#applications-of-lists",
    "title": "2  Lists",
    "section": "2.2 Applications of Lists",
    "text": "2.2 Applications of Lists\n\nStoring and processing any kinds of data\nConcrete representation of abstract data types such as: set, graph, etc…",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lists</span>"
    ]
  },
  {
    "objectID": "03/01-lists.html#linked-and-doubly-linked-lists",
    "href": "03/01-lists.html#linked-and-doubly-linked-lists",
    "title": "2  Lists",
    "section": "2.3 Linked and Doubly Linked Lists",
    "text": "2.3 Linked and Doubly Linked Lists\n\n\n\n\nsimply linked\ndoubly linked\n\n\n\n\nlecture\nSList\nList\n\n\nc++\nstd::forward_list\nstd::list\n\n\n\nDoubly linked lists are usually simpler and require “only” double the space at most. Therefore their use is more widespread.\n\nList Items\nClass Item of T :=\n    e: T //Data item of type T\n    next: *Item //Pointer to Item\n    prev: *Item //Pointer to Item\n    invariant next-&gt;prev = this = prev-&gt;next\n\nProblem: * predeccessor of first list element? * successor of last list element?\nSolution: Dummy Item with an empty data field as follows:\n\nAdvatanges of this solution:\n\nInvariant is always satisfied\nExceptions are avoided, thus making the coding more:\n\nsimple\nreadable\nfaster\nelegant\n\n\nDisadvantages: a little more storage space.\n\n\nThe List Class\nClass List of T :=\n    dummy := (\n        Null : T\n        &dummy : *T // initially list is empty, therefore next points to the dummy itself\n        &dummy : *T // initially list is empty, therefore prev points to the dummy itself\n    ) : Item\n\n    // returns the address of the dummy, which represents the head of the list\n    Function head() : *Item :=\n        return address of dummy\n    \n    // simple access functions\n    // returns true iff list empty\n    Function is_empty() : Bool := \n        return dummy.next == dummy \n\n    // returns pointer to first Item of the list, given list is not empty\n    Function first() : *Item :=\n        assert (not is_empty())\n        return dummy.next\n    \n    // returns pointer to last Item of the list, given list is not empty\n    Function last() : *Item :=\n        assert (not is_empty())\n        return dummy.prev\n\n    /* Splice is an all-purpose tool to cut out parts from a list\n       Cut out (a, ... b) form this list and insert after t */\n    Procedure splice(a, b, t : *Item) := \n        assert (\n            b is not before a \n            and \n            t not between a and b\n        )\n        // Cut out (a, ... , b)\n        a-&gt;prev-&gt;next := b-&gt;next\n        b-&gt;next-&gt;prev := a-&gt;prev\n\n        // insert (a, ... b) after t\n        t-&gt;next-&gt;prev := b\n        b-&gt;next := t-&gt;next\n        t-&gt;next := a\n        a-&gt;prev := t\n\n    \n    // Moving items by utilising splice\n    //Move item a after item b\n    Procedure move_after(a, b: *Item) := \n        splice(a, a, b)\n    \n    // Move item a to the front of the list\n    Procedure move_to_front(a: *Item) := \n        move_after(a, dummy)\n\n    Procedure move_to_back(a: *Item) :=\n        move_after(b, last())\n\n    // Deleting items by moving them to a global freeList\n    // remove item a\n    Procedure remove(a: *Item) :=\n        move_after(b, freeList.dummy)\n    \n    // remove first item\n    Procedure pop_front() :=\n        remove(first())\n\n    //remove last item\n    Procedure pop_back() :=\n        remove(last())\n\n    // Inserting Elements\n    // Insert an item with value x after item a\n    Function insert_after(x : T, a : *Item) : *Item := \n        checkFreeList() //make sure freeList is non empty\n        b := freeList.first() // obtain an item b to hold x\n        move_after(b, a) // insert b after a\n        b-&gt;e := x // set the data item value of b to x\n        return b\n\n    // Manipulating whole lists\n    Procedure concat(L : List) :=\n        splice(L.first(), L.last(), last()) //move whole of L after last element of this list\n\n    Procedure clear()\n        freeList.concat(this) //after this operation from from first to last element of this\n                              // list are concatenated to the freeList, leaving only the \n                              // dummy element in this list.\n\n    Fuction get(i )\n\n    \n\n    \n\nSplicing\nThe code for splicing of the List class:\n/* Splice is an all-purpose tool to cut out parts from a list\n    Cut out (a, ... b) form this list and insert after t */\nProcedure splice(a, b, t : *Item) := \n    assert (\n        b is not before a \n        and \n        t not between a and b\n    )\n    // Cut out (a, ... , b)\n    a-&gt;prev-&gt;next := b-&gt;next\n    b-&gt;next-&gt;prev := a-&gt;prev\n\n    // insert (a, ... b) after t\n    t-&gt;next-&gt;prev := b\n    b-&gt;next := t-&gt;next\n    t-&gt;next := a\n    a-&gt;prev := t\n\nDlist cut-out \\((a,...,b)\\) (see Figure 2.1):\n\n\n\n\n\n\n\nFigure 2.1: cutout\n\n\n\n\nDlist insert \\((a,...,b)\\) after \\(t\\) (see Figure 2.2):\n\n\n\n\n\n\n\nFigure 2.2: insert\n\n\n\n\n\nSpeicherverwaltung ./.FreeList\nMethods (?):\n\nNiavely: allocate memory for each new element, deallocate memory after deleting each element:\n\nadvantage: simplicity\ndisadvantage: requires a good implementation of memory management: potentially very slow\n\n“global” freeList (e.g. static member in C++)\n\ndoubly linked list of all not used elements\ntransfer ‘deleted’ elements in freeList.\ncheckFreeList allocates, in case the list is empty\n\n\nReal implementations: * naiv but with well implemented, efficient memory management * refined Free List Approach (class-agnostic, release) * implementation-specific.\n\n\nDeleting Elements\nDeleting elements realised by moving them to the global freeList:\nProcedure remove(a: *Item) :=\n    move_after(a, freeList.dummy) // item a is now a 'free' item. \n\nProcedure pop_front() :=\n    remove(first())\n\nProcedure pop_back() :=\n    remove(last())\n\n\nInserting Elements\nInserting elements into a list \\(l\\) also utilizes freeList, by fetching its first element an moving it into \\(l\\).\nFunction insert_after(x : T, a : *Item) : *Item := \n    checkFreeList() //make sure freeList is non empty\n    b := freeList.first() // obtain an item b to hold x\n    move_after(b, a) // insert b after a\n    b-&gt;e := x // set the data item value of b to x\n    return b\n\nFunction insert_before(x : T, b : *Item) : *Item :=\n    return insert_after(x, b-&gt;prev)\n\nProcedure push_front(x : T) :=\n    insert_after(x, dummy)\n\nProcedure push_back(x : T) :=\n    insert_after(x, last())\n\n\nManipulating whole Lists\n// Manipulating whole lists\nProcedure concat(L : List) :=\n    splice(L.first(), L.last(), last()) //move whole of L after last element of this list\n\nProcedure clear()\n    freeList.concat(this) //after this operation from from first to last element of this\n                            // list are concatenated to the freeList, leaving only the \n                            // dummy element in this list.\nThis operations require constant time - indeendent of the list size!",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Lists</span>"
    ]
  },
  {
    "objectID": "03/02-arrays.html",
    "href": "03/02-arrays.html",
    "title": "3  Arrays",
    "section": "",
    "text": "3.1 Bounded Arrays\nBounded arrays have fixed size and are an efficient data structure.",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "03/02-arrays.html#bounded-arrays",
    "href": "03/02-arrays.html#bounded-arrays",
    "title": "3  Arrays",
    "section": "",
    "text": "Size must be known during compile time and is fixed.\nIts memory location in the stack allows many compiler optimizations.",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "03/02-arrays.html#unbounded-arrays",
    "href": "03/02-arrays.html#unbounded-arrays",
    "title": "3  Arrays",
    "section": "3.2 Unbounded Arrays",
    "text": "3.2 Unbounded Arrays\nThe size of an unbounded array can dynamically change during run-time. From the user POV it provides the same behaviour as a linked list.\nIt allows the operations:\n\npushBack(e: T): insert an element at the end of the array\npopBack(e: T): remove an element at the end of the array\n\n\nMemory Management\n\nallocate(n): request a \\(n\\) contigious blocks of memory words and returns the address value of the first block. This we have the memory blocks:\n\n\n\narray memory allocation\n\n\nwhere ptr + i addresses are determined by pointer arithmetic.\ndispose(ptr) marks the memory address value held in ptr as free, effectively deleting the object held there.\n\nIn general, the allocated memory can’t grow dynamically during life time, since the immediate memory block after the last one might get unpredictably occupied \\(\\Rightarrow\\) If we need a new memory block of size \\(n' &gt; n\\), we must allocate a new block, copy the old block contents, and finally free it.\n\n\nImplementation\nFirst we consider a slow variant:\nClass UArraySlow&lt;T&gt;:=\n  c := 0 : Nat // capacity\n  b : Array[0..c-1]&lt;T&gt; // the array itself\n\n  pushBack(el : T) : void :=\n    // c++\n    // allocate new array on heap with new capacity\n    // copy elements over from the old array\n    // insert el at the last location\n  \n  popBack() : void := \n    // analagous\nProblem: \\(n\\) pushBack operations require \\(1 + \\dots + n \\in \\mathcal{O}(n^2)\\) time \\(\\Rightarrow\\) slow.\nSolution:\n\nUnbounded Arrays with Extra Memory\nIdea: Request more memory than initial capacity. Reallocate memory only when array gets full or too empty:\nAlgorithm design principle: make common case fast.\nClass UArray&lt;T&gt; := \n  c := 1 : Nat // capacity\n  n := 0 : Nat // number of elements in the array\n\n  //invariant n &lt;= c &lt; k*n || (n == 0 && c &lt; 2)\n  b : Array[0..c-1]&lt;T&gt;\n\n  // Array access\n  Operator [i : Nat] : T := \n    assert(0 &lt;= i &lt; n)\n    return b[i]\n\n  // accessor method for n\n  Function size() : Nat := return n\n\n  Procedure pushBack(e : T) := \n    if n == c :\n      reallocate(2*n) // see definition below\n    b[n] := e\n    n++\n\n  // reallocates a new memory with a given capacity c_new\n  Procedure reallocate(c_new : Nat) := \n    c := c_new \n    b_new := new Array[0..c_new - 1]&lt;T&gt;\n    //copy elements over to new array\n    for (i = 1 to n - 1) :\n      b_new[i] := b[i]\n    dispose(b)\n    b := b_new \n\n  Procedure popBack() :=\n    // don't do anything for empty arrays\n    assert n &gt; 0\n    n--\n    if 4*n &lt;= c && n &gt; 0 :\n      reallocate(2*n)",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Arrays</span>"
    ]
  },
  {
    "objectID": "05/01-sorting.html",
    "href": "05/01-sorting.html",
    "title": "4  Sorting and Priority Queues",
    "section": "",
    "text": "4.1 Sorting Algorithms",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sorting and Priority Queues</span>"
    ]
  },
  {
    "objectID": "05/01-sorting.html#sorting-algorithms",
    "href": "05/01-sorting.html#sorting-algorithms",
    "title": "4  Sorting and Priority Queues",
    "section": "",
    "text": "Insertion Sort\n\ndef insertion_sort(a) :\n    n = len(a)\n    # i = 1\n    # sorted a[0..i-1]\n    for i in range(1, n) :\n        # insert i in the right position\n        j = i - 1\n        el = a[i]\n        while el &lt; a[j] and j &gt; 0 :\n            a[j + 1] = a[j]\n            j = j - 1\n        # el &gt;= a[j] or j == 0\n        if el &lt; a[j] : # j == 0\n            a[1] = a[0]\n            a[0] = el\n        else : # el &gt;= a[j] \n            a[j + 1] = el\n    return a\n\ntesting insertion sort for some inputs:\n\nimport numpy as np\nfor i in range (2, 8) :\n    randarr = np.random.randint(1, 20, i)\n    print(\"in:  \", randarr)\n    print(\"out: \", insertion_sort(randarr))\n\nin:   [17 18]\nout:  [17 18]\nin:   [ 7 15  8]\nout:  [ 7  8 15]\nin:   [ 9  6  2 11]\nout:  [ 2  6  9 11]\nin:   [13  7  7 17  3]\nout:  [ 3  7  7 13 17]\nin:   [12  6  6  6 18 11]\nout:  [ 6  6  6 11 12 18]\nin:   [19  9  6 14  1  4 11]\nout:  [ 1  4  6  9 11 14 19]\n\n\nFollowing illustrates the state after each insertion (ith iteration):\n\ndef insertion_sort_print(a) :\n    n = len(a)\n    # i = 1\n    # sorted a[0..i-1]\n    for i in range(1, n) :\n        # insert i in the right position\n        j = i - 1\n        el = a[i]\n        while el &lt; a[j] and j &gt; 0 :\n            a[j + 1] = a[j]\n            j = j - 1\n        # el &gt;= a[j] or j == 0\n        if el &lt; a[j] : # j == 0\n            a[1] = a[0]\n            a[0] = el\n        else : # el &gt;= a[j] \n            a[j + 1] = el\n        print(\"after insertion \", i, \": \", a)\n    # return a\n\n\na = np.random.randint(-20, 20, 8)\nprint(\"input:               \", a)\ninsertion_sort_print(a)\n\ninput:                [ -8   4   5  -6   0 -13 -20   0]\nafter insertion  1 :  [ -8   4   5  -6   0 -13 -20   0]\nafter insertion  2 :  [ -8   4   5  -6   0 -13 -20   0]\nafter insertion  3 :  [ -8  -6   4   5   0 -13 -20   0]\nafter insertion  4 :  [ -8  -6   0   4   5 -13 -20   0]\nafter insertion  5 :  [-13  -8  -6   0   4   5 -20   0]\nafter insertion  6 :  [-20 -13  -8  -6   0   4   5   0]\nafter insertion  7 :  [-20 -13  -8  -6   0   0   4   5]\n\n\n\n\nSelection Sort\nexplanation:\n\n\n\nselection sort\n\n\npython implementation:\n\ndef selection_sort(a) :\n    N = len(a)\n    j = 0\n    # sorted a[0..j-1] && a[0..j-1] &lt;= a[j..N-1]\n    while (j &lt; N) :\n        # find min a[j..N-1]\n        k = j\n        min = a[k]\n        i = j + 1\n        #a[k] == min == min(a[j .. i - 1])\n        while (i &lt; N) :\n            if a[i] &lt; min :\n                min = a[i]\n                k = i\n            i = i + 1\n        # k = j + find_min(a[j :])\n        a[j], a[k] = a[k], a[j]\n        j = j + 1\n    return a\n\nwe test this on some random arrays:\n\nfor i in range (2, 8) :\n    randarr = np.random.randint(-50, 50, i)\n    print(\"in:  \", randarr)\n    print(\"out: \", selection_sort(randarr))\n\nin:   [ 23 -26]\nout:  [-26  23]\nin:   [-44  36  23]\nout:  [-44  23  36]\nin:   [-35 -18  41 -50]\nout:  [-50 -35 -18  41]\nin:   [-48  43 -28  47   3]\nout:  [-48 -28   3  43  47]\nin:   [-50  34  -6  28 -10  -4]\nout:  [-50 -10  -6  -4  28  34]\nin:   [-29  20  48  16 -27  -4   5]\nout:  [-29 -27  -4   5  16  20  48]\n\n\n\n\nBubble Sort\nLet a : Array[0..N-1]&lt;Nat&gt;. The bubble operation pushes the largest element to the end of the array:\n\ndef bubble(a) :\n    N = len(a)\n    i = 0\n    # a[i] == max(a[0..i])\n    while i &lt; N - 1:\n        if a[i] &gt; a[i + 1] :\n            a[i], a[i+1] = a[i+1], a[i]\n        i = i + 1\n    # post-loop: i == N - 1\n    return a \n\nbubble([-5, 10, 1, 3, 7, -2])\n\n[-5, 1, 3, 7, -2, 10]\n\n\nThe code of this function is used inside bubble_sort():\n\ndef bubble_sort(a) :\n    N = len(a)\n    j = N\n    swapped = False\n    while True : # emulate do while loop\n        # sorted a[j .. N - 1] and a[0..j-1] &lt;= a[j .. N - 1] \n        while j &gt; 0 :\n            i = 0\n            while i &lt; j - 1 :\n                if a[i] &gt; a[i + 1] :\n                    a[i], a[i + 1] = a[i + 1], a[i]\n                i = i + 1\n            j = j - 1\n        if not swapped : break # if no swaps performed at all, array already\n                               # sorted \n    return a\n\nWe test on some arrays:\n\nfor i in range (2, 8) :\n    randarr = np.random.randint(-50, 50, i)\n    print(\"in:  \", randarr)\n    print(\"out: \", bubble_sort(randarr))\n\nin:   [ 3 25]\nout:  [ 3 25]\nin:   [  6 -11  23]\nout:  [-11   6  23]\nin:   [-48  -6   1   2]\nout:  [-48  -6   1   2]\nin:   [-14 -21  37 -43 -15]\nout:  [-43 -21 -15 -14  37]\nin:   [ 20 -16 -29  33 -14  36]\nout:  [-29 -16 -14  20  33  36]\nin:   [  4  13  36  20 -42  13 -38]\nout:  [-42 -38   4  13  13  20  36]\n\n\nVisual expalantion:\n\n\n\nbubble sort\n\n\n\n\nMerge Sort\nGiven by the following python implementation:\n\ndef merge(a, b) :\n    # assert: a and b are sorted\n    c = []\n    n1 = len(a)\n    n2 = len(b)\n    k1 = 0\n    k2 = 0\n    i = 0\n    # invariant: merged a[0..k1 - 1] with b[0..k2 - 2]\n    while k1 &lt; n1 and k2 &lt; n2 :\n        if a[k1] &lt;= b[k2] :\n            c.append(a[k1])\n            k1 = k1 + 1\n        else :\n            c.append(b[k2])\n            k2 = k2 + 1\n    # k1 &gt;= n1 or k2 &gt;= n2\n    if k1 == n1 :\n        while k2 &lt; n2 :\n            c.append(b[k2])\n            k2 = k2 + 1\n    if k2 == n2 :\n        while k1 &lt; n1 :\n            c.append(a[k1])\n            k1 = k1 + 1\n    return c\n        \ndef merge_sort(a) :\n    if len(a) == 1 : return a[0:1]\n    n = len(a)\n    a1 = a[0 : n // 2]\n    a2 = a[n // 2 : ]\n    return  merge(merge_sort(a1), merge_sort(a2))\n\nWe test on some arrays:\n\nfor i in range (2, 8) :\n    randarr = np.random.randint(-20, 20, i)\n    print(\"in:  \", randarr)\n    print(\"out: \", merge_sort(randarr))\n\nin:   [ -6 -14]\nout:  [-14, -6]\nin:   [  5  16 -14]\nout:  [-14, 5, 16]\nin:   [ 13 -13  18   0]\nout:  [-13, 0, 13, 18]\nin:   [  9   2  -9 -14 -15]\nout:  [-15, -14, -9, 2, 9]\nin:   [-2  8  3 -1 -5 19]\nout:  [-5, -2, -1, 3, 8, 19]\nin:   [-10  18 -13 -10  -6 -13 -16]\nout:  [-16, -13, -13, -10, -10, -6, 18]\n\n\n\n\nQuick Sort\nNaively:\n\ndef quicksort(s) :\n    if len(s) &lt;= 1 : return s\n    p = s[len(s) // 2]\n    a = []\n    b = []\n    c = []\n    for i in range(0, len(s)) :\n        if s[i] &lt; p : a.append(s[i])\n    for i in range(0, len(s)) :\n        if s[i] == p : b.append(s[i])\n    for i in range(0, len(s)) :\n        if s[i] &gt; p : c.append(s[i])\n    return quicksort(a) + b + quicksort(c)\n\ntesting this naive implementation for some arrays:\n\nfor i in range (2, 8) :\n    randarr = np.random.randint(-10, 20, i)\n    print(\"in:  \", randarr)\n    print(\"out: \", quicksort(randarr))\n\nin:   [-9 12]\nout:  [-9, 12]\nin:   [19 -5 -6]\nout:  [-6, -5, 19]\nin:   [-3 13 13 11]\nout:  [-3, 11, 13, 13]\nin:   [-7 -8 16 -8 11]\nout:  [-8, -8, -7, 11, 16]\nin:   [ 14 -10  -3  -9  18  14]\nout:  [-10, -9, -3, 14, 14, 18]\nin:   [ 8  1 16 14 16  3 15]\nout:  [1, 3, 8, 14, 15, 16, 16]\n\n\n\nQuicksort Refinements\npseudocode:\nProcedure qSort(a : Array&lt;T&gt;; l, r : Nat) := \n    while r - l + 1 &gt; n0 :\n        j := pick_pivot_pos(a, l, r)\n        swap(a[l], a[j]) // pivot is at the first position\n        p := a[l]  // p is the value of the pivot\n        i := l; j := r\n        do\n            while a[i] &lt; p : i++; //skip over the elements \n            while a[j] &gt; p : j--; // already in the correct subarray\n            if i &lt;= j : \n                swap(a[i], a[j])\n                i++\n                j--\n        while i &lt;= j\n        qSort(a, l, j)\n        qSort(a, i, r)\ncpp implementation including testing for {3, 6, 8, 1, 0, 7, 2, 4, 5, 9}\n#include &lt;iostream&gt;\n\nvoid qSort(int* a, int l, int r)\n{\n    if (r &lt;= l) return;\n    int p = a[0]; // first element is pivot\n    int i = l;\n    int j = r;\n    do {\n        while (a[i] &lt; p) i++;\n        while (a[j] &gt; p) j--;\n        if (i &lt;= j) {// partitioning is not complete \n            int temp = a[i];\n            a[i] = a[j];\n            a[j] = temp;\n            i++;\n            j--;\n        }\n    } while (i &lt;= j);\n    // i &gt; j\n    qSort(a, l, j);\n    qSort(a, i, r);\n}\n\nint main(int argc, const char** argv) {\n    int a[] = {3, 6, 8, 1, 0, 7, 2, 4, 5, 9};\n    for (int i = 0; i &lt; 9; i++)\n        std::cout &lt;&lt; a[i] &lt;&lt; \", \"; \n    std::cout &lt;&lt; a[9] &lt;&lt; std::endl;\n    return 0;\n}",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sorting and Priority Queues</span>"
    ]
  },
  {
    "objectID": "05/01-sorting.html#priority-queues-and-heap-data-structure",
    "href": "05/01-sorting.html#priority-queues-and-heap-data-structure",
    "title": "4  Sorting and Priority Queues",
    "section": "4.2 Priority Queues and Heap Data Structure",
    "text": "4.2 Priority Queues and Heap Data Structure\nA set \\(M\\) of Elements \\(e : T\\) with Keys supporting two operations:\n\ninsert(e): Insert \\(e\\) into \\(M\\).\ndelete_min(): remove the min element from \\(M\\) and return it.\n\n\nApplications\n\nGreedy algorithms (selecting the optimal local optimal solution)\nSimulation of discrete events\nbranch-and-bound search\ntime forward processing.\n\n\n\nBinary Heaps\nHeap Property:\n\nFor any leaf \\(a \\in M\\) \\(a\\) is a heap.\nLet \\(T_1,\\, T_2\\) be heaps. If \\(a \\leq x, \\, \\forall x\\in T_1, T_2\\), then \\(T_1 \\circ a \\circ T_2\\) is also a heap.\n\nComplete Binary Tree:\n\nA complete binary tree is a binary tree in which ever lebel, except possibly the last, is completely filled, and all nodes in the last level are as far left as possible.\n\nHeap:\n\nA heap is a complete binary tree that satisfies the heap property:\nA heap can be succinctly represented as an array:\n\n\n\n\nheap\n\n\n\nArray h[1..n]\nfor any given node with the number j:\n\nleft child: 2*j\nright child 2*j + 1\nparent: bottom(j/2)\n\n\nPseudocode:\nClass BinaryHeapPQ(capacity: Nat)&lt;T&gt; :=\n    h : Array[1..capacity]&lt;T&gt;\n    size := 0 : Nat // current amount of elements\n\n    // Heap-property\n    // invariant: h[bottom(j/2) &lt;= h(j)], for all j == 2..n\n\n    Function min() :=\n        assert size &gt; 0 // heap non-emtpy\n        return h[1]\n    \n    Procedure insert(e : T) :=\n        assert size &lt; capacity\n        size++\n        h[size] := e\n        siftUp(size)\n    \n    Procedure siftUp(i : Nat) := \n        // assert Heap-property violated at most at position i\n        if i == 1 or h[bottom(i / 2)] &lt;= h[i] then return\n        swap(h[i], h[bottom(i/2)])\n        siftUp(bottom(i/2))\n    \n    Procedure popMin : T :=\n        result = h[1] : T\n        h[1] := h[size]\n        size--\n        siftDown(1)\n        return result\n    \n    Procedure siftDown (i : Nat) :=\n        // assert: Heap property is at most at position 2*i or 2*i + 1 violated\n        if 2i &gt; n then return // i is a leaf\n\n        // select the appropriate child\n        if 2*i + 1 &gt; n or h[2*i] &lt;= h[2*i + 1] : \n        //no right child exists or left child is smaller than right\n            m := 2*i\n        else : m := 2*i + 1\n        if h[i] &gt; h[m] :\n            swap(h[i], h[m])\n            siftDown(m)\n\n    Procedure buildHeap(a[1..n]&lt;T&gt;) :=\n        h := a\n        buildRecursive(1)\n\n    Procedure buildHeapRecursive(i : Nat) :=\n        if 4*i &lt;= size : // children are not leaves\n            buildHeapRecursive(2*i) // assert: heap property holds for left subtree\n            buildHeaprecursive(2*i + 1) // assert: heap property holds for right subtree\n        siftDown(i) //assert Heap property holds for subtree starting at i \n    \n    //alternatively\n    Procudure buildHeapBackwards :=\n        for i := n/2 downto 1 :\n            siftDown(i)\n\n    Procedure heapSort(a[1..n]&lt;T&gt;) :=\n        buildHeap(a) // O(n)\n        for i := n downto 2 do : \n            h[i] := deleteMin(); // O(log(n))\n\nHeap Insert\nProcedure insert(e : T) :=\n    assert size &lt; capacity\n    size++\n    h[n] := e\n    siftUp(n)\n\nProcedure siftUp(i : Nat) := \n    // assert Heap-property violated at most at position i\n    if i == 1 or h[bottom(i / 2)] &lt;= h[i] then return\n    swap(h[i], h[bottom(i/2)])\n    siftUp(bottom(i/2))\nIllustration of heap insert:\n\n\n\nheap insert\n\n\n\n\nHeap Pop Min (or Delete Min)\n Procedure popMin : T :=\n        result = h[1] : T\n        h[1] := h[n]\n        n--\n        siftDown(1)\n        return result\n    \nProcedure siftDown (i : Nat)\n    // assert: Heap property is at most at position 2*i or 2*i + 1 violated\n    if 2i &gt; n then return // i is a leaf\n\n    // select the appropriate child\n    if 2*i + 1 &gt; n or h[2*i] &lt;= h[2*i + 1] : \n    //no right child exists or left child is smaller than right\n        m := 2*i\n   if h[i] &gt; h[m] :\n            swap(h[i], h[m])\n            siftDown(m)   else : m := 2*i + 1\nIllustration of pop min:\n\n\n\nheap pop min\n\n\n\n\nConstruction of a Binary Heap\n\nGiven are \\(n\\) numbers. Construct a heap from these numbers\nNaive Solution: \\(n\\) calls to insert() \\(\\Rightarrow\\) \\(\\mathcal{O}(n\\log(n))\\)\n\nProblem: If numbers are given in an array, we can’t perform the construction in place.\nIt is slow\n\nwe can do faster and in place in \\(\\mathcal{O}(n)\\) time.\n\nPseudocode for recursive implementation:\n Procedure buildHeap(a[1..n] : T) :=\n        h := a\n        buildRecursive(1)\n\nProcedure buildHeapRecursive(i : Nat) :=\n    if 4*i &lt;= n : // children are not leaves\n        buildHeapRecursive(2*i) // assert: heap property holds for left subtree\n        buildHeaprecursive(2*i + 1) // assert: heap property holds for right subtree\n    siftDown(i) //assert Heap property holds for subtree starting at i \nA simpler iterative one-liner:\n Procudure buildHeapBackwards :=\n        for i := n/2 downto 1 :\n            siftDown(i)\n\\(\\lfloor i/2 \\rfloor\\) is the last non-leaf node.\nTime complexity of these binary heap construction algorithms is \\(\\mathbfcal{O}(n)\\).\n\n\nHeapsort\nProcedure heapSort(a[1..n]&lt;T&gt;) :=\n        buildHeap(a) // O(n)\n        for i := n downto 2 do : \n            h[i] := deleteMin(); // O(log(n))\nSorts in decreasing order in \\(\\mathcal{O}(n\\log(n))\\), by removing the minimal element and writing the return value to the end of the array in place.",
    "crumbs": [
      "Data Structures",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Sorting and Priority Queues</span>"
    ]
  }
]